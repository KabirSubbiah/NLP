{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KabirSubbiah/NLP/blob/main/Dependency_Parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFyK0hfPGKdV"
      },
      "source": [
        "# üîÆ ‚û°Ô∏è Assignment 5: Shift-Reduce Dependency Parser\n",
        "In this assignment, you'll be implementing a dependency parser using the Shift-Reduce algorithm described in lecture on grammars and parsing. In Part 1, you'll implement the basic algorithm, with a dummy \"oracle\" that just uses the ground-truth labels. Then, you'll train a classifier to act as an actual oracle in Part 2, and evaluate the results of that model in Part 3. Have fun shifting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpc3bVYqGUlx"
      },
      "source": [
        "# [DO NOT EDIT] Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HMNSWAfyExKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5de2aee-d03c-4221-9268-3871605f4655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.19.1 multiprocess-0.70.15\n"
          ]
        }
      ],
      "source": [
        "!pip install torch tqdm numpy datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SmPBF_yIFbwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2eb2a0-9e96-47ee-9c0d-17ed52a706be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dfb443bd2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random, torch, tqdm\n",
        "\n",
        "from datasets import load_metric\n",
        "from google.colab import output\n",
        "from numpy.typing import NDArray\n",
        "from torch.optim import Optimizer as TorchOptimizer\n",
        "from torch.utils.data import DataLoader as TorchDataLoader\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "output.enable_custom_widget_manager()\n",
        "random.seed(1460)\n",
        "np.random.seed(1460)\n",
        "torch.manual_seed(1460)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFKVMSPW9D8U"
      },
      "source": [
        "# Part 1: Basic Algorithm with Ground-Truth Oracle\n",
        "\n",
        "Read through the following sections to understand the setup here, and then complete the TODO sections. We will define several helper functions for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxsdi7nh36zR"
      },
      "source": [
        "## TODO: Download the data\n",
        "\n",
        "We will be using two files for this assignment: `train.conll` and `test.conll`. You can download [`train.conll` here](https://drive.google.com/file/d/1Yky_NVpL0wKFpA8604TCRbT4CSKidCqK/view?usp=drive_link) and [`test.conll` here](https://drive.google.com/file/d/1J7W_cof5fCroGbC-pLIxUTCvgIDy8ufL/view?usp=drive_link). Drag them into the 'Files' sidebar in this Colab to use them in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVLpnEEDO95P"
      },
      "source": [
        "## Loading Data\n",
        "The datasets for this assignment come in a particularly strange format, called CoNLL. We've handled parsing it, but we encourage you to check out the format so that you'll understand it if you ever need to work with it. All that you need to know is that `read_conll` returns a list of dictionaries, where each dictionary encodes a parsed sentence. Each dictionary has a `'words'` key, which maps to a list of words which make up the sentence, and `'heads'` key, which maps to a list of integers, where the value at index `i` is the index of the word that is word `i`'s head. The root word has a head value of `None`.  \n",
        "\n",
        "So the sentence '1460 is awesome.' would have the words `['1460', 'is', 'awesome', '.']` (yes, the punctuation is included), with heads `[2, 2, None, 2]`. Check out the visual below which illustrates the dependency parse (arrows going out of one word and into another mean that that first word is the head of the other):\n",
        "\n",
        "![Screenshot 2022-11-21 164002.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJ8AAAAxCAYAAADEDXt+AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABK+SURBVHhe7ZwJdBRVusf/nT0hERLCGvawv4eySVgVUQRkHFQWEYGjjj5QXlREQEdwIUFwZAQPinKcg4pBRZR1BsQFEIkQhk18SBIghGBIAlnIQjpr97v/L1Wd7pB0upOQANM/uOfW/e6trltV//ruVhWDWQEXLhoANy124aLecYnPRYPxHy++jIwMREREwGg0apbKbS7qHpfnq4SmTZti4cKF8PX11SwurgU3jfjWrVsHg8EgYebMmeK1oqOjLTbmW3u0uLg4LF++XPZNTk7GoEGDpBz3cXm++uGm8nxRUVHg4L1bt25ISkrCwYMHERsbK7ZHH31UK1U5P/74I9LT07Fr1y4UFBRoVhfXkutWfMePH8eiRYtwzz33oFWrVnB3d7d4MeswcuRIbQ+gQ4cO2lYZ9913Hx5++GEpR09WFSEhIfDz85NA8vPzJSZ33XXXVcdk8PDwQGhoKKZPn47NmzdrpV04w3UnPnqgsWPHSsjJycGLL76Iw4cPo7i4WDxYxfD9999re14NPeCxY8csYsrMzJSY0Mvl5eXJNptdltHL6SIku3fvrvS49I47duzA4MGDsWzZMoSFhUnaheNcN+LLzs7GU089JeGhhx7C+fPn5aaOHj0arVu3hpub81Wlt6OXopg6deqELl26iJ1pelV/f39Jk7vvvhvBwcEYMWIEfHx8NGvV0PN17dpV+pf79u3DnDlzMGPGDLz88staCRfVop7iBkf1s8ydO3c2z54922wymTRrw6G8olmJ06w8oWZxjMuXL5vHjRtnnjx5smZxYY8G93yffvopRo0ahcjISLzzzjviqRoSjnQ5OKGndHaqpXHjxtL/a9SokXhvF9WgibBeef311yV+//33zaqzb46JiZH0zYQaiJgfe+wxLXVjQs/PVuBaUe/iUx14vshgvv/++83t2rUznzhxQsu5+VAjccuDdiMSFRVlVv1ZLVX31Lv4eDMoPob+/ftr1obl448/rtRL8eKznrfddps5NjZWPIEaVIiNMdO8OXPnzpUyqvtg4ykuXrxobtOmjXnjxo2a5drCY7Mu7HOyjqybdf+V56C6NmJjXfX7oAuM5ZhmXnx8vMT6uVvDa1UXD1W99/m2bt2qbUFGm3v27NFSDcMnn3yCxx9/HImJiZqlDPb9fv75Z5mSWb9+PbZv3w4lIgwbNkymWhgzTTgltH//flmS+/bbb8VGmjVrho8++gjh4eFIS0vTrNcWzhIoYVQ7Yc45UZbhJDwn47nik5ubK9NNPA/apk2bBtU1kimrivAYb7zxhpaqGR5abJf9/zqL76NOISOlfPLVWby83RHaLwBHjhyRk/nwww8xfPhwLfdqeIPfPLgAR1IOotBUqFnrhua+LTC2zUPYvTpaLi7hQ8AplsLCQixYsABTp06VenKdl4HbXI7jxDVRXlsEyZtIIXJwwqka3jSiD1buvPNODBw4EMojYe3atTCZivF/x+chK/MgSksdOy83N08EBvZDz15vwtPzFrEdPXoUK1askDqwLs899xxuv/129OzZE6o7I2UIxVQZ+sS6DoWovJzUe8iQIRK4JKnz4IMPymCK+fqyIwWouk149tln5b7ygdXhwJEP37333muZ4qqIQ+Jbv+wYpoWP1lI15/iheAwfPAa7o7drlqr57uw/UepVhEdHTdcsdcua7atw4MuTMqrlDUpNTRWB6CshvJD0BvoFXbVqFVQTikOHDokQGTdv3lzyEhISJOYN1G28Qfxd3rBXXnlFtulBB4WZ1GjYC7fe+qyUc5TzSXFISlyD0C7PY/Xq1XjmmWewdOlSvPXWW2jZsqWUYV31CXOdigLTJ9Yrwgdny5YtMkrn0iRFrZ8L2bRpk8R8MBcvXizbgYGBOHDggLQAFVsOQgF+9tlneOmllzSLLQ41u2aTtqHxjw1L0H+8n4TwiD8jO7ds5cDaXjGPFF4xYdHclVqqenJM2dj75S8SrLkQn4K1r3yJxN+SMCdsAcb7TbeE2P2npAz3sbYzWP+O6u3KzThz5gxSUlLE01ovwdHbsdnhTdEnn1VfSppiXlTG+nQKn37auD8nxXV446dMmSJLhfQCFExJaanKuVxWwIrlK7YrsV/QUmXY2ngdvfDBBx9gyZIlsnLDh0UXnjXWE+b0cKSyiXVr+EDR87EclyTp4enVZ82aJQ+hDpc7ea0YuGJEob766qtari0sYw+n+3wUWEiLjjj0Tb6EJye+jPc/fw2FRUb4+fjjm5XHKs2rKX3uvRVpZy+hyFikWYDTR85iwJ/6qabcE8OnDsU3+WslrDz2Fg7+87CUvWPyYIv9i4x/YPLC8fJbzsCmR7/Q3GaTw+4C04z1plWN3MXG/h5FW5GAgADExMTIEuEzs97VrM6zd+/vmDdvnizj9erVS7PaQrGx/6nXmbAPx/TOnTsxe/Zsm1fGKDraCOc3WY7Cpp3769s69rpKzuKU+HQvNmLgOInJbd0H4a8zVsLb6+oJ2e6desPf9xakpp/XLM4TEFT2pCYcOycxhUUxhnRrJemKdB/UFV6+XlqqrPyXkRsxZPwAy281BJx4XrNmjRLAIRw+nKpZHSc3txCL3/xaJuV79OihWW9snBLf5dx08W6VCa0yWC448OpmwVl6De+J3/b8Ltu6CHUh7YnaZ2lWw3vPx7nfbIW+ZcUO8ZKtu1Yu1tpC71Dd61o6EyZMQN8+XdCvn/PXJCDAGwMGdLG7cmLt0W4EnBJfk4Bg5BfkXdWM/hq7X9uyheXSs5x/yivSqXd7iXMz80SEFKOOdbPL5tWYZ5Q+IdmwZIuU7T6o8tFWQ7BpY82nJyIWPaJt3Rw4Jb7GAUES7zqwRWJC4bEfaD2w0IlNOIY8Yw5aBrfVLDWDzWiLjs1w8pd4SetirAxff18EBAfI4IL7XE/Cq0iE6g5ER8epkXGRGvRkVWm7WXF6wMFBRHLaWcuIlsKLfP4TESa94vjw3pa8f/30OeY8/jeHm2l7dO7bEesjNoqgrPt01s3uI02ftHjFnz6PxrtPfGjJY6AnvJ6YNHEgZoWvgZ//dNWssvPfulLbjQIntDkNwxkER3Doo/Hn79pUJ/N8Mbti0eueWzDsgVDNUjU7E7Zh7+Uf0K9Hf81St3y8/SNsG79XS9UfSYlfqFFvDEJDB2kWxzifdAxFxe0R2mWmZrl+4BTOE088oaVs4UT1/PnztZQtDomPKxzfrT2FzLTarXB07dscf4kcADf36l+bYrUWxczHr6lHUGQqn2apC4J9gzGu60Q8GFr/faiyFY4XkJV5GKWljp2Xm5sHAgN7o2evv1lWOK4nOI/JpbysrPJuAuc9OQDivGdVKxy8ybXGeKXIPH/sFi1V/3x54lPze/9epqVuXE7FvWeO/f0tLXVjsnTpUnNqaqqWso/dPl9JcYWlDQ2zyYwrOUXISLmClLPZOPLjH+jwX0GI3pqg0jliZ76ptHKnyv1rC1coiLEkH7nFOSgsLUBhSdkiuqniksw1w7nzMJUWqiZX1bUwHcb8ZGRnH8eVK4nIzDgozXFBwUWUqPM5lxiFjPQDyMtLQG7uaTX4SEZhwSXZt1Sdp7PHrU+UplQduYpTPZZmN/n0ZfxxOhtxhy8iqIUf8nOLlOsEigrKfsinkScKrhTLtt8tqsOvdvP194KPvweahQSgffcgnIvNRPqFPBhzi2FkWfXL/B3i46f2zy/b38PLnUdWnWovXErOQ8+wlggJbYy2XQMl3x5nsuJxKisWf2Sfo29X/91QaiqFu5u7Gj0ZLKL09fTDA10nwdejfG3Tccxy0wuMKSguykJxSZ6cb4mKS02F6uEpsrwUYDaXSKzj4dFIlbuipcrx9Gyi9jHC3d0bBjcvVV9vFKnf9mvUXppSb59m8PNrCzeDuxJkkhKoEltRNgoKU1VZX9Vcq2Nqx3Z381H9v6uX6Dw9GyuBZmupctzd+U2KQXV3vNXvq2MzVnVgXT3UPj4+LdDIv6Oka8LZs2dlLfvcuXM4ffq0fHPTu3dv+c6lffuqZyZEfKmJOdi7+Qx6DwtRF8aA5m39RWzevg69d1AjKGqKOe18jrqDBvwWfQG3j2yHtt3sC3DdiTXo0qQbBoSULR1Zo4uwoMSIHWe2IjSwK25t3kfLdZyUCzuQk30CjRv/txJHW3h6BUpfjYKRG6iJx6D6YjcCZnOpiJeelwLmNs+BQjXmX0BuTqwSij/atp8s/Utn4do2R7r9+vXTLJCPqlq0aFF1f0/h+hNpLhoMp+f5XLiwhzO+zMbzFeWrfk0R3+LQDPUA+5XuXgZ4+zn+1VqJuRj55nyUwra/RVTPBt4Gb/gaatLXs4Z9Vi4jXn2Mmwv6H9UnNFT/rbI9TCaTJeh/XaK6b60tuRRecWH9Co/weCXquHzXzxHU6SHPnFup8IhZ5Rco0TDUHFUXdYybX3iE1z1fnW/t5lJ14RGOdh3xgBbx0eM1JCXq3B0RfrHyel99vgEvPD1HjUar/oM+hebavHpft5PaNwa1F581TonPuuyp03F47MkpyMwsfye/Iiwz6I6+WPp2pGYp50BMNPyD3CWwDMvqGAuMeO6Fpy353KbNUejZHKMWD5MjT8HNhqFuz9kp8RFdUH0G9MTly1W/UUFRLl76Bpo3K3/HX4di/GJ9FC5dyENeZin27z2CLp3L34R9d+Xf0apViOQxcJs2Z5g4ZQLe+eDv8PGtXT/FRcNiIz6KhGL5YUfVC+4U3hP/MxUzn5qFQQOHatYyKN7YuN/x2oJI+Ppc/SYL8/cf2IfxD07ULMDwO+4ST2nPy1Zkw+df2zS7mRmZmDBmEoLcgyXc0fdOnIo7LXk1JU7t37vPnTC4NbWE6OgYyctQxxs9ZqLDaRIRsczyO8xjGZ116zbYHIdldfgb1nnWv8n9ZqrrMG/+6zb7Wu9T8VjEXl3qExvxVYcuvJfmLsDAsKsneY8cPYysrEyMfWBklc1qYGAQmgYFaym+fRssLjojM12zOAcFGLlgMR6eNgmZpekSwl8MR0a642KujG7dOuPY0Z9gNmVIiPrsQ0RELpMb1bRpEIYMDkNiYpKUjY09hZ07d2HXrp8lnZ6eqc6zCbp3L5tg5c1OvpCC/CvJ8lvc9xVVZ6OqO4XyWdRXSL90SvIYE+bxAVgU8TZiT8ZIHmOmaddZvfoTjPvzGEv+Nxu3ye/xWAwdOrTDqlVrtNL26lKbAVrNcFh81QmPnE1MQIf2HbHru2hpUtn0kpf++oIIMCMj3W5zXhsSE8o/3WOzPHBImJaqG/r37yMPCYVFOnVqj5/3HRCRUHSbN0XJTaU4Dx06ip49+M1vkKR/PxmH2c8/DV+tmzBp0gPIzs6xfOKYmnrR8rvcZ+HCF6XsV19txtAhA+VBIIyZpl1nxozH0LfvbbIdHByEli2bY9rUSbI/w7ChA6VerKf9ulzH4qNnSruYhnvG3GHxapFLXpPwwIQxlmaTfTi9yWX8yMNTcS4pEUZ1oenlmjSpfv3WGdjve0ZdzG3qideb3epGwo5i3Tx17xGGtLRLWk6ZGHnTzp9Plps7dGgYQlq3Ei+YkHBOxEkoqpMn42V/69+ijXlD1EMy/qH7bfKtm9a6xH5datdS1ASHxaf3B/WBAsOCl9+QsPnrHQgKaoqOHTohJSXZ7uiVzbJ1E0tvKO9+WTXFztJZeYS9R36SJvf0xXgkJZ7H1k3btNyaUbF5YpPWokUzLRdo164N2rYNwZ49+0R09FgjRgzDlq07kJuXJ+LU4X5606kHNum6R6On0+3Wzfu1oOq61P/nBk71+apj5N2jxMtt3Vb2dTtFyJEvm2mKkwLmIOWbTRskn+zZu9uSXxM42Hhb3Szd0/Gj53YdavfNCPs/FB6bLL15YlNq7floD/D3x4yZL4joCPt4x4+fkMAmkOhN5fIVH0jTRxhT3BQYBw3Wno59NB02ifuiD1j6eIyZpr0mVFeX2vLLL7/In+yIjy/71qY6bMSnT7Wwaf1h13do17m5TZNaHRTQ20tXYMXKZdIsN2vtL80w+4k6z4XPEe+oN93cpq2mBCmPQ1r7t5Eml3GrkFaYNKV8RO0s/PSQ/aK3l71naZ5+VYKy9nyEohs1aoRlYKEPRBi4rUPPRu/o14hvDTWVmLAMPeSs/51nOQ63312xRPIollcXzrU0k4yZ1j1mTbBXl/rGsrabf9nU4HOrfk3cZK3XHly5yDeXDWTs4QZ3NHZroqWcRXkFc80/Gbgx8VJqqPlH9UVFtiskXNfl+3z2sHg+Dy/HF/avBR48dweq4GnwhEH9qw6+XFBzyr+O+8+hdufMlwmsYT++Oizi8/IzwNObbwZrhnqCx/NQx/Vu5Fj300398zcEKL9W+VPFt1p8DL4Sao6qizqGqllZ8qaG191PnW/txEdPp7/FYr1tD9fLpC4aCOD/AdflyFhhN5uDAAAAAElFTkSuQmCC)\n",
        "\n",
        "As you can see, 'awesome' is the root word, and its head is hence the value `None`. 'awesome' is also the head of all of the other words, you can see this since the `'heads'` values corresponding to the other words are all `2`, which is the index of the word 'awesome' in the word list!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KBPvso44FcLj"
      },
      "outputs": [],
      "source": [
        "def read_conll(in_file: str, lowercase: bool = False,\n",
        "               max_example: Optional[int] = None) -> List[Dict[str, Any]]:\n",
        "  \"\"\"\n",
        "  Function that reads in a CoNLL file and produces example parses.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  in_file : str\n",
        "      file path to a .conll file\n",
        "  lowercase : bool\n",
        "      determines whether to lowercase words in the \"words\" string\n",
        "  max_example : Optional[int]\n",
        "      the maximum number of examples to process, or None to process all\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  List[Dict[str, Any]]\n",
        "      a list of examples taken from the .conll file\n",
        "  \"\"\"\n",
        "\n",
        "  examples = []\n",
        "  with open(in_file) as f:\n",
        "    word, pos, head, label = [], [], [], []\n",
        "    for line in f.readlines():\n",
        "      sp = line.strip().split('\\t')\n",
        "      if len(sp) == 10:\n",
        "        if '-' not in sp[0]:\n",
        "          word.append(sp[1].lower() if lowercase else sp[1])\n",
        "          pos.append(sp[4])\n",
        "          head.append(int(sp[6]) - 1)\n",
        "          label.append(sp[7])\n",
        "      elif len(word) > 0:\n",
        "        examples.append({'words': word, 'pos': pos, 'heads': head, 'label': label})\n",
        "        word, pos, head, label = [], [], [], []\n",
        "        if (max_example is not None) and (len(examples) == max_example):\n",
        "          break\n",
        "    if len(word) > 0:\n",
        "      head[head.index(-1)] = None\n",
        "      examples.append({'words': word, 'pos': pos, 'heads': head, 'label': label})\n",
        "  return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq7-FI5d6Zn-"
      },
      "source": [
        "## (DO NOT EDIT) Ground-Truth Dummy Oracle\n",
        "This function has been written for you, please do not edit it! It takes the current stack, buffer, root word, as well as the full parse (read from the CoNLL), and returns the ground-truth correct action (arc left, arc right, or shift) to be taken by the Shift-reduce algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nBmYxfY267lR"
      },
      "outputs": [],
      "source": [
        "def get_ground_truth_oracle(stack: List[int], buf: List[int],\n",
        "                            ex: Dict[str, Any]) -> Optional[int]:\n",
        "  \"\"\"\n",
        "  Function that retrieves the best possible action (arc left, arc right, or shift)\n",
        "  for a given stack, buffer, and ground truth parsing.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  stack : List[int]\n",
        "      the shift-reduce stack\n",
        "  buf : List[int]\n",
        "      the shift-reduce buffer\n",
        "  ex : Dict[str, Any]\n",
        "      Raw training example dict produced by read_conll()\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Optional[int]: {None, 0, 1, 2}\n",
        "      action to apply in shift-reduce algorithm\n",
        "      None -> no actions can be taken\n",
        "      0 -> arc left\n",
        "      1 -> arc right\n",
        "      2 -> shift\n",
        "  \"\"\"\n",
        "\n",
        "  if len(stack) == 1:\n",
        "      return None if len(buf) == 0 else 2\n",
        "  elif len(stack) == 2:\n",
        "      return 1 if len(buf) == 0 else 2\n",
        "\n",
        "  sf = stack[-1]\n",
        "  ss = stack[-2]\n",
        "  hf = ex['heads'][sf]\n",
        "  hs = ex['heads'][ss]\n",
        "\n",
        "  if hs == sf:\n",
        "    return 0\n",
        "  elif hf == ss and (not any([True for x in buf if ex['heads'][x] == sf])):\n",
        "    return 1\n",
        "  else:\n",
        "    return None if len(buf) == 0 else 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtipchT53jb1"
      },
      "source": [
        "\n",
        "**VERY IMPORTANT:**\n",
        "\n",
        "\n",
        "We need to train models using supervised learning to drive our shift-reduce algorithm. To do this, we'll break the parsing of an entire sentence down into steps, called _partial parses_. At each step a classifier will have to decide, given some features, whether to arc left, arc right, or shift. Each partial parse can be labeled with the correct action, and we can train the model to execute partial parses as well as possible!\n",
        "\n",
        "The input to our model is a set of features, from which the correct partial parse is to be predicted. Our model will use learned word embeddings, and will classify between three classes. The model will have an embedding layer, which can be used to fetch learned embeddings for words, based on their ID. As such, the model takes some number of integers, each less than the length of the vocabulary, as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ4Lt3kxVzKp"
      },
      "source": [
        "## word_to_id\n",
        "Since we need to build up a vocabulary when training, and assign an ID/index to each word, we need some functions to handle doing so. We'll first define word_to_id, which when in `is_test=False` mode, both builds a vocabulary as well as returns the IDs of known words. When `is_test=True`, unknown words are not used to expand the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YfBhLxCMVpAF"
      },
      "outputs": [],
      "source": [
        "def word_to_id(word: str, vocab: Dict[str, int], is_test: bool = False) -> int:\n",
        "  \"\"\"\n",
        "  Function that converts a string `word` to its corresponding ID in `vocab`.\n",
        "  If not in testing mode, also adds `word` to vocab.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  word : str\n",
        "      the word in question\n",
        "  vocab : Dict[str, int]\n",
        "      vocabulary mapping words to their ID\n",
        "  is_test : bool\n",
        "      whether to operate in testing or training mode\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  int\n",
        "      the ID of `word`\n",
        "  \"\"\"\n",
        "\n",
        "  if is_test:\n",
        "    if word in vocab:\n",
        "      return vocab[word]\n",
        "    else:\n",
        "      return vocab[\"<UNK>\"]\n",
        "\n",
        "  # otherwise, we're doing train:\n",
        "\n",
        "  if word in vocab:\n",
        "    if random.randint(0, 100) <= 5:\n",
        "      return vocab['<UNK>'] # randomly mask this word for training example, otherwise <UNK> never trained on.\n",
        "    return vocab[word]\n",
        "\n",
        "  else:\n",
        "    n = len(vocab)\n",
        "    vocab[word] = n\n",
        "    return n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_RzctwMteya"
      },
      "source": [
        "## TODO: `apply_action`\n",
        "This is a helper function that applies a given action (arc left, arc right, or shift) to the current stack, buffer, and arcs. It should modify these and return the new stack, buffer, and arcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2x9lMIZizSE-"
      },
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import noncentral_chisquare\n",
        "from datasets.utils.py_utils import NonMutableDict\n",
        "from datasets.info import NonMatchingCachedSizesError\n",
        "def apply_action(stack: List[int], buf: List[int], arcs: List[Tuple[int, int]],\n",
        "                 action: int) -> Tuple[List[int], List[int], List[Tuple[int, int]]]:\n",
        "  \"\"\"\n",
        "  Function that applies `action` to the current state. Modifies stack, buf, and\n",
        "  arcs accordingly and returns the new state. stack, buf, and arcs contain the\n",
        "  indices of words in an example sentence, where an index of None represents the\n",
        "  root.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  stack : List[int]\n",
        "      the current shift-reduce stack. stack[-1] is the top of stack, stack[-2] is\n",
        "      the second item\n",
        "  buf : List[int]\n",
        "      the current shift-reduce buffer. buf[0] is the first item in the buffer\n",
        "  arcs : List[Tuple[int, int]]\n",
        "      the current arcs produced by shift-reduce (of the form (head idx, word idx))\n",
        "  action : int\n",
        "      the action we want to apply\n",
        "      0 -> arc left\n",
        "      1 -> arc right\n",
        "      2 -> shift\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Tuple[List[int], List[int], List[Tuple[int, int]]]\n",
        "      the updated stack, buffer, and arcs\n",
        "  \"\"\"\n",
        "\n",
        "  head_idx = None\n",
        "  word_idx = None\n",
        "\n",
        "  match (action):\n",
        "    case 0:\n",
        "      head_idx = stack[-1]\n",
        "      word_idx = stack.pop(-2)\n",
        "\n",
        "    case 1:\n",
        "      head_idx = stack[-2]\n",
        "      word_idx = stack.pop(-1)\n",
        "\n",
        "    case 2:\n",
        "      stack.append(buf.pop(0))\n",
        "\n",
        "    case _:\n",
        "      print(\"Unreachable case reached\")\n",
        "\n",
        "  if (word_idx != None):\n",
        "    arcs.append((head_idx, word_idx))\n",
        "\n",
        "  return stack, buf, arcs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTCqTkM_8kKJ"
      },
      "source": [
        "## TODO: `is_possible`\n",
        "`is_possible` returns whether an action (arc or shift) is possible given the current stack and buffer. This will be used in part 2 once we start training an oracle using machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rkiPf0cVHJMz"
      },
      "outputs": [],
      "source": [
        "def is_possible(action: int, stack: List[int], buf: List[int]) -> bool:\n",
        "  \"\"\"\n",
        "  Function that determines if a given action is possible given the current stack\n",
        "  and buffer state. Remember that stack and buf contain the indices of words in\n",
        "  an example sentence, where an index of None represents the root. Think carefully\n",
        "  about this function; it is likely to be a source of errors. Work through the\n",
        "  example in the slides and try to replicate that logic here. Be particularly\n",
        "  careful with the root (None). Can anything be the head of root? Should we ever\n",
        "  perform an arc with the root while there are still words in the buffer?\n",
        "  Remember that at the beginning of the shift-reduce algorithm, stack and buf\n",
        "  will look like:\n",
        "      stack = [None]\n",
        "      buf = [0, 1, 2, ...]\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  action : int\n",
        "      the action we want to know is possible\n",
        "      0 -> arc left\n",
        "      1 -> arc right\n",
        "      2 -> shift\n",
        "  stack : List[int]\n",
        "      the shift-reduce stack\n",
        "  buf : List[int]\n",
        "      the shift-reduce buffer\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  bool\n",
        "      whether or not the given action is possible\n",
        "  \"\"\"\n",
        "\n",
        "  match (action):\n",
        "    case 0:\n",
        "      if stack[-1] == None or stack[-2] == None:\n",
        "        return False\n",
        "      return True\n",
        "\n",
        "    case 1:\n",
        "      if len(stack) < 2:\n",
        "        return False\n",
        "\n",
        "      if len(stack) == 2:\n",
        "        if len(buf) == 0:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "      return True\n",
        "\n",
        "    case 2:\n",
        "      if len(buf) == 0:\n",
        "        return False\n",
        "      else:\n",
        "        return True\n",
        "\n",
        "    case _:\n",
        "      print(\"Invalid action given as input\")\n",
        "      return False\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tamGi2Gh7D0x"
      },
      "source": [
        "## TODO: `get_features`\n",
        "This is a featurization function - it takes in the stack, buffer, words to be parsed, and vocabulary (as well as an `is_test` flag) and returns a featurization to be passed to the classifier. This featurization should consist of three word IDs to be converted to embeddings.\n",
        "\n",
        "You may decide how to featurize the stack and buffer such that the classifier executes partial parses with the best results possible, **however our autograder will expect a feature vector of length three**. `stack` and `buf` are both lists of integers that represent indices of strings in the list `words` (with `None` representing the root node). Use these indices to get the corresponding word strings, and then use `word_to_id` to convert words to their IDs. **Note**: for the root use the `'<ROOT>'` token. Remember that our features are in terms of **word ids** in our `vocab`, not **word indices** that the `stack` and `buf` contain!\n",
        "\n",
        "Keep in mind that you must always output the same number of features. If one of your features is the first word in the buffer, but the buffer is empty, you can provide the ID corresponding to the `'<NW>'` ('no word') token to fill its place!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "inKn3jWEtI32"
      },
      "outputs": [],
      "source": [
        "def get_features(stack: List[int], buf: List[int], words: List[str],\n",
        "                     vocab: Dict[str, int], is_test: bool = False) -> List[int]:\n",
        "  \"\"\"\n",
        "  Function that takes in the current state (stack, buffer) and produces a set of\n",
        "  features to be fed into a classifier. Think about what information our\n",
        "  classifier would need to know in order to predict an optimal action from the\n",
        "  current state. Hint: you should only need 3 features\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  stack : List[int]\n",
        "      the shift-reduce stack\n",
        "  buf : List[int]\n",
        "      the shift-reduce buffer\n",
        "  words : List[str]\n",
        "      words in the sentence, in order\n",
        "  vocab : Dict[str, int]\n",
        "      the word id vocabulary\n",
        "  is_test : bool\n",
        "      whether we are in testing mode\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  List[int]\n",
        "      A list of three integers to be fed into the classifier\n",
        "      Hint: use word_to_id on the items of the data structures\n",
        "  \"\"\"\n",
        "  features = []\n",
        "\n",
        "  if len(stack) == 1:\n",
        "    features.append(word_to_id(\"<ROOT>\", vocab, is_test))\n",
        "    features.append(word_to_id(\"<NW>\", vocab, is_test))\n",
        "\n",
        "    word3 = \"<NW>\" if len(buf) == 0 else words[buf[0]]\n",
        "    features.append(word_to_id(word3, vocab, is_test))\n",
        "\n",
        "  else:\n",
        "    word1 = words[stack[-1]]\n",
        "    features.append(word_to_id(word1, vocab, is_test))\n",
        "\n",
        "    word2 = \"<ROOT>\" if stack[-2] == None else words[stack[-2]]\n",
        "    features.append(word_to_id(word2, vocab, is_test))\n",
        "\n",
        "    word3 = \"<NW>\" if len(buf) == 0 else words[buf[0]]\n",
        "    features.append(word_to_id(word3, vocab, is_test))\n",
        "\n",
        "  return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jxkUbuNz0gnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f381d9b5-d12d-45fa-9592-34706190af61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "# feel free to test your bow_features here! Modify this example as much as you want\n",
        "# original: \"I prefer the morning flight through Denver .\"\n",
        "example = {'words': \"I prefer the morning flight through Denver .\".split(\" \"), 'heads': [1, None, 4, 4, 1, 6, 1, 1]}\n",
        "fake_vocab = {'<ROOT>': 0, '<UNK>': 1, '<NW>': 2, \"I\": 3, \"prefer\": 4, \"the\": 5, \"morning\": 6, \"flight\": 7, \"through\": 8, \"Denver\": 9, \".\": 10}\n",
        "# simulate some part of the process, edit stack and buf as you want\n",
        "stack = [None]                   # stack initialized with root index\n",
        "buf = [0, 1, 2, 3, 4, 5, 6, 7] # buf initialized with word indices\n",
        "is_test=False\n",
        "features = get_features(stack, buf, example['words'], fake_vocab, is_test)\n",
        "assert len(features) == 3\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN_mkd-T6Yii"
      },
      "source": [
        "## TODO: `oracle_shift_reduce`\n",
        "This is one of the two implementations of shift reduce in this assignment. It applies the regular shift-reduce algorithm to generate partial parses for training, as well as the correct arcs for a labeled example.\n",
        "\n",
        "Apply the shift-reduce algorithm, making use of the functions `get_ground_truth_oracle`, `get_features`, and `apply_action` (and possibly more!), in order to both produce a full parse of the input example as well as labeled partial parses. In other words, for each partial parse along the way, we want you to save that state in `featurized_states` with the featurization from your `get_features` function, as well as the \"gold\" action produced by the ground-truth oracle.\n",
        "\n",
        "Remember to handle the case where `get_ground_truth_oracle` returns `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N9BY2UXDs_xq"
      },
      "outputs": [],
      "source": [
        "from logging import BufferingFormatter\n",
        "def oracle_shift_reduce(example: Dict[str, Any], vocab: Dict[str, int],\n",
        "                        is_test: bool = False) -> Tuple[List[List[int]], List[int], List[Tuple[int, int]]]:\n",
        "  \"\"\"\n",
        "  Function that executes the ideal shift reduce algorithm determined by the oracle\n",
        "  on a single example and returns a set of features and labels to pass into the classifier.\n",
        "  This function will be called for every example parse to generate our training\n",
        "  data.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  example : Dict[str, Any]\n",
        "      a training example produced by read_conll\n",
        "  vocab : Dict[str, int]\n",
        "      the vocabulary\n",
        "  is_test : bool\n",
        "      whether the function is being used to generate training or testing data.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Tuple[List[List[int]], List[int], List[Tuple[int, int]]]\n",
        "      featurized states, ground truth actions, and final set of arcs.\n",
        "      We're not going to need the arcs when generating the data, but they'll\n",
        "      be useful later on when we assess our model's performance!\n",
        "  \"\"\"\n",
        "\n",
        "  featurized_states = []\n",
        "  ground_truth_actions = []\n",
        "\n",
        "  # initialize stack, buffer, and arcs\n",
        "  stack = [None]\n",
        "  buf = [i for i in range(len(example['heads']))]\n",
        "  arcs = []\n",
        "\n",
        "  while len(buf) > 0 or len(stack) > 1:\n",
        "\n",
        "    action = get_ground_truth_oracle(stack, buf, example)\n",
        "\n",
        "\n",
        "    if action != None:\n",
        "      featurized_states.append(get_features(stack, buf, example['words'], vocab, is_test))\n",
        "      apply_action(stack, buf, arcs, action) #Remaking of structures can be done with return\n",
        "      ground_truth_actions.append(action)\n",
        "    else:\n",
        "      break\n",
        "      print(f\"While loop broken by None return with {len(buf)} remaining elements in buf and {len(stack)} remaining elements in stack\")\n",
        "\n",
        "\n",
        "  return featurized_states, ground_truth_actions, arcs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ROnsQoWBOXj"
      },
      "source": [
        "# Part 2: Machine Learned Oracle\n",
        "Above, you implemented a version of shift-reduce that assumed you had a ground-truth oracle. Of course, in practice, you will never have this! So, in order to run your parser on unseen data, you will need to implement another version of the oracle--this time using machine learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGYdV-h3-kJj"
      },
      "source": [
        "## `generate_training_data`\n",
        "First, we need to get training data to train our machine-learned oracle. To do this, we can use our ground truth oracle from above to generate training/testing instances (labeled partial parses) for us to train our classifier on. This essentially entails applying `oracle_shift_reduce` to every example in the raw data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vg_4j2qzFeIe"
      },
      "outputs": [],
      "source": [
        "def generate_training_data(raw_data: List[Dict[str, Any]], vocab: Dict[str, int],\n",
        "                           is_test: bool = False) -> Tuple[List[List[int]], List[int]]:\n",
        "  \"\"\"\n",
        "  Function that generates training data and labels from a list of examples\n",
        "  produced by read_conll().\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  raw_data : List[Dict[str, Any]]\n",
        "      a list of example parses loaded with read_conll\n",
        "  vocab : Dict[str, int]\n",
        "      the vocabulary to use\n",
        "  is_test : bool\n",
        "      whether to create testing or training data\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Tuple[List[List[int]], List[int]]\n",
        "      a set of featurized states and corresponding ground truth actions\n",
        "  \"\"\"\n",
        "\n",
        "  X, Y = [], []\n",
        "\n",
        "  for i, element in enumerate(raw_data):\n",
        "    featurized_states, ground_truth_actions, arcs = oracle_shift_reduce(element, vocab, is_test)\n",
        "    X.extend(featurized_states)\n",
        "    Y.extend(ground_truth_actions)\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrfMUh7uPp0_"
      },
      "source": [
        "### Dataset objects\n",
        "Since this assignment uses Pytorch modules as the classifiers for the shift-reduce algorithm, we'll make a dataset child class for our data, such that we can eventually make PyTorch Dataloaders (just as in assignment 4)! This has been implemented for you.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eCX9rMHFPspz"
      },
      "outputs": [],
      "source": [
        "# def of Dataset child obj to use with DataLoader\n",
        "class SRDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X: List[List[int]], Y: List[int]) -> None:\n",
        "    \"\"\"\n",
        "    Function that initializes fields for the dataset. Anything you need in\n",
        "    `__init__()` or `__getitem__()` should be saved here by defining any\n",
        "    number of self.*\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : List[List[int]]\n",
        "        our featurized data from `generate_training_data()`\n",
        "    Y : List[int]\n",
        "        one-hot encoded labels corresponding to each entry in X\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    self.X = np.zeros((len(X), len(X[0])), dtype='int32')\n",
        "    self.Y = np.zeros((len(Y), 3), dtype='float32')\n",
        "    for i, class_num in enumerate(Y):\n",
        "      self.X[i] = X[i]\n",
        "      self.Y[i, class_num] = 1\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\"\n",
        "    Function that returns the number of training examples.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    self : refers to the current object\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        the number of entries in X\n",
        "    \"\"\"\n",
        "    return len(self.Y)\n",
        "\n",
        "  def __getitem__(self, idx: int) -> Dict[str, NDArray[Any]]:\n",
        "    \"\"\"\n",
        "    Function that defines how to retrieve an entry and a label from the data given\n",
        "    and index.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    idx : int\n",
        "        the index of an example in X or Y\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, NDArray[Any]]\n",
        "        a dictionary defining the example and corresponding label described by\n",
        "        index `idx`\n",
        "    \"\"\"\n",
        "    return {'inputs': self.X[idx], 'targets': self.Y[idx]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY_4RN-9sl5v"
      },
      "source": [
        "### Training Function\n",
        "\n",
        "Here we define our function for training the model. This has been implemented for you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u5rwjT0rKGDi"
      },
      "outputs": [],
      "source": [
        "def train(model: torch.nn.Module, dataloader: TorchDataLoader, epochs: int,\n",
        "          optimizer: TorchOptimizer, metric_names: List[str]) -> None:\n",
        "  \"\"\"\n",
        "  Function that trains our classifier.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      the classifier we want to train\n",
        "  dataloader : torch.utils.data.DataLoader\n",
        "      the dataloader containing our training data\n",
        "  epochs : int\n",
        "      number of epochs to train the model\n",
        "  optimizer : torch.optim.Optimizer\n",
        "      the optimizer to user for training\n",
        "  metric_names : List[str]\n",
        "      list of metric names to compute\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"epoch {epoch}\")\n",
        "    progress_bar = tqdm.notebook.tqdm(range(len(dataloader)))\n",
        "\n",
        "    metrics = [load_metric(x) for x in metric_names]\n",
        "\n",
        "    for batch in dataloader:\n",
        "      batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "      outputs = model(**batch)\n",
        "\n",
        "      loss = loss_func(outputs['output'], outputs['labels'])\n",
        "      loss.backward()\n",
        "\n",
        "      predictions = torch.argmax(outputs['output'], dim=1)\n",
        "      references = torch.argmax(outputs['labels'], dim=-1)\n",
        "\n",
        "      for metric in metrics:\n",
        "        metric.add_batch(predictions=predictions, references=references)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      progress_bar.update(1)\n",
        "\n",
        "    for metric in metrics:\n",
        "      print(metric.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXA1BqmP7SHR"
      },
      "source": [
        "## TODO: `SRClassifier`\n",
        "Now, let's design a simple neural classifier to train on the partial parse classification task.\n",
        "\n",
        "It needs to have an embedding layer of size `vocab_size`, with embedding dimension of your choosing. After converting your word ids to embeddings, make sure you concatenate them together into one long vector so that they play nicely with your linear layers. We've provided a `num_features` argument such that you can make your classifier work with any number of input word IDs (which will make your life easier if you use it). Then, it's going to need several linear layers and activation functions (two hidden layers should be enough), eventually ending with three output classes (corresponding to our three possible actions). In `forward`, we need to specify how the model will be applied to input features.\n",
        "\n",
        "PyTorch documentation will be very helpful here! You should look at the `torch.nn.Embedding` layer for word embeddings, you may find the examples helpful in figuring out what to do with its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sJj2JJLZIOaz"
      },
      "outputs": [],
      "source": [
        "# model that takes input in format given by SRDataset\n",
        "class SRClassifier(torch.nn.Module):\n",
        "  def __init__(self, vocab_size: int, num_features: int) -> None:\n",
        "    \"\"\"\n",
        "    Function that initializes fields for this model. This is where you can\n",
        "    your model's architecture.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    vocab_size : int\n",
        "        the number of words in our vocabulary\n",
        "    num_features : int\n",
        "        the number of features for each training example (same as length of the\n",
        "        list returned by `get_features()`)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    print(f\"Vocab size: {vocab_size}\")\n",
        "    super(SRClassifier, self).__init__()\n",
        "    self.num_features = num_features\n",
        "    self.embedding = torch.nn.Embedding(vocab_size, 100)\n",
        "\n",
        "    self.linear1 = torch.nn.Linear(self.num_features*100, 100)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "\n",
        "    self.linear2 = torch.nn.Linear(100, 20)\n",
        "    self.relu2 = torch.nn.ReLU()\n",
        "\n",
        "    self.linear3 = torch.nn.Linear(20, self.num_features)\n",
        "\n",
        "\n",
        "  def forward(self, inputs: torch.IntTensor,\n",
        "              targets: Optional[torch.IntTensor] = None) -> Dict[str, torch.FloatTensor | torch.IntTensor]: # notice that the arg names need to match SRDataset.__getitem__() keys\n",
        "    \"\"\"\n",
        "    Function that defines the forward pass for this model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    inputs : torch.IntTensor\n",
        "        a tensor passed into our model. When training/testing, the torch\n",
        "        dataloader automatically casts our numpy arrays to tensors.\n",
        "    targets : Optional[torch.IntTensor]\n",
        "        a tensor representing labels for each training example in `inputs`. If\n",
        "        not training, this parameter can be None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, torch.FloatTensor | torch.IntTensor]\n",
        "        a dictionary containing our model's output and corresponding labels.\n",
        "    \"\"\"\n",
        "    embed = self.embedding(inputs)\n",
        "\n",
        "\n",
        "    lin_1 = self.linear1(embed.view(-1, self.num_features*100))\n",
        "    lin_2 = self.linear2(self.relu1(lin_1))\n",
        "    outputs = self.linear3(self.relu2(lin_2))\n",
        "\n",
        "    return {'output': outputs, 'labels': targets}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKuQeNknCndl"
      },
      "source": [
        "## TODO: Training the classifier\n",
        "Let's initialize some required data that will be used in training. This includes our vocabulary, which will be built when loading training data. By default, the vocabulary should map `'<UNK>'`, `'<NW>'`, and `'<ROOT>'` to start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3PZ-EWTxF4AG"
      },
      "outputs": [],
      "source": [
        "vocabulary = {'<ROOT>': 0, '<UNK>': 1, '<NW>': 2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yJq_LDmJrTS"
      },
      "source": [
        "We load the training data using `read_conll`, generate training data using `generate_training_data` and instantiate a `SRDataset` object with them. Finally, create a dataloader with the `SRDataset` object - the batch size can be very high, but if you somehow run out of memory, you should decrease it. *Nothing TODO here!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SXRTivhOItsW"
      },
      "outputs": [],
      "source": [
        "raw_training_data = read_conll('train.conll')\n",
        "\n",
        "X_train, Y_train = generate_training_data(raw_training_data, vocabulary)\n",
        "\n",
        "train_dataset = SRDataset(X_train, Y_train)\n",
        "train_dataloader = TorchDataLoader(train_dataset, batch_size=1024)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SmL_By00IQXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2e0484-c844-4494-8d9f-5a27623b7610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 2, 3], [3, 0, 4], [4, 3, 5], [5, 4, 6], [6, 5, 7], [7, 6, 8], [7, 5, 8], [7, 4, 8], [7, 3, 8], [7, 1, 8]]\n",
            "[2, 2, 2, 2, 2, 0, 0, 0, 0, 2]\n"
          ]
        }
      ],
      "source": [
        "# At this point, each partial parse should be a n-tuple of integers.\n",
        "print(X_train[:10])\n",
        "print(Y_train[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oVSBx6kKISj"
      },
      "source": [
        "Next, let's instantiate our classifier and set up training hyperparameters and the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7TovLnTJ4wB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586,
          "referenced_widgets": [
            "4b08d44531fd42869ebf57ca49c5cdb4",
            "18edc01a7f044098baf08ddf59e84f77",
            "34cdb37a383c42d69011f7487c8d54ec",
            "3a24df6efc3b42dfb788c52aedd1cf58",
            "fe23141485bb442293ce090165342c51",
            "620c305ab31142c0ae3f50db8d5b04b3",
            "6ea26680627d4976be43b00bd236867a",
            "d6ce14000deb420da4ae0e425e83be48",
            "75e65f7f34a34e49ac756da0bfbad18c",
            "7179b5b15ecc4d6daafa2bca091a6f9e",
            "0edf89f1c4f34cfba92a3da32aae0a64",
            "5b77dbd8c73f4210b50cecc05a1944ba",
            "43944429ce824e859a498485a7735e5c",
            "0a511e13156844d886be1c826081a9bc",
            "77655841d8b5479d91e23dbafdb9facd",
            "1023c651431549cda299a0ca3f973d79",
            "60866d5b62d7469484bea75436ea8c98",
            "9778bbc1d93c4c10b9d94d114d0f30e7",
            "77ba2119440a487ca55ff75502ff599b",
            "23e5be392fc447ec9853741cd7bfa395",
            "d24b1479ffef42ed94f2a44035e52250",
            "5fff0008d3e94c1c87b388945f1836c1",
            "06f8da5c3fcb4c6b8fe1cc9def2cb76b",
            "3b79fd6833e34f7997e48db3940c235f",
            "183b9fa2fc1642488c94b6d2476bef90",
            "3c1b04350b314902845abe15ecdef420",
            "641717f97dfd4d8da8b2981e239b1add",
            "bd30897f4ad44aaa87731b216f2a12d1",
            "81b5650adb104130bce2ce14c0547b15",
            "d20f0a3bbdc64ccc85cdec1e1d42f985",
            "4e592b10ea8a4a668c250d97c2121980",
            "2f2890d334bb40a1abacabc79411286a",
            "61409cb1c0354d1f9c4506ea10cb530f",
            "4b21be59abbd4a1590f03554cc2f3159",
            "ba7a65096b3f495b8fe592405348cc91",
            "0f4e468938e34ac78392caafc4e57c30",
            "df61f576e9004a3aacab8660f600cde4",
            "3d06bd65ef4c416184c51b55dc73780d",
            "142b61b77d6d43688054531481284881",
            "3ee21c6dad034a64ad8423ccdf3a0bb1",
            "0ba33faafc924da298cd29073e9956fd",
            "d86cc9526321403c895e5f8f76f5e5d5",
            "f5b9a617689e438f85f373b9ad308266",
            "d9e4c873bf0144219f990a3a53d5d65a",
            "05e30a2ff9804d0aaf5a1fcfd4087912",
            "81fc197c9851485f8d99d1c7e805a996",
            "2ecc88db3214439db4a43368a8b9231a",
            "a7318698d2a346da9661e669cd82b962",
            "cd05603628a247c08e4aa8aab4494e14",
            "9957d2a7778f4e42a627a6f8c7c36c06",
            "c73e558ee4844f808057e0c5c998f14b",
            "76f3922eb171443387dca4bf2f81ac2f",
            "9c4a01058ebd43969dbd4ca0610257b7",
            "9c3c8d6358b24cc2b7cdd6777f56ca96",
            "0a22d20e801b416e9623fa51d5b26a51",
            "f6ccef61bda445618d81b7076c8b48c9",
            "330898310df6496ca68f35531c50ce98",
            "de66e34d5acd45a3834237b6c7358854",
            "b73d99eff4f94ba2aa65c7d06805f0f6",
            "3ad7694ef57441608ec5877e9c6f9f24",
            "e5a0cb870e30456f94b43ff0a76b15fc",
            "72734e033887472290c84d8e0c447f55",
            "f3fe611655314879bcb5efcae3da43bc",
            "170b6ffedfcb42408d8099c405f3f956",
            "974a72ae732f43fe858a2ae12ffa0f18",
            "1c31f6b6f2e64872a058a662fa054b1d"
          ]
        },
        "outputId": "ff90fa5b-a1b7-4827-c832-e4e99061febb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 29162\n",
            "SRClassifier(\n",
            "  (embedding): Embedding(29162, 100)\n",
            "  (linear1): Linear(in_features=300, out_features=100, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (linear2): Linear(in_features=100, out_features=20, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (linear3): Linear(in_features=20, out_features=3, bias=True)\n",
            ")\n",
            "epoch 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/853 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b08d44531fd42869ebf57ca49c5cdb4"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-d61de69313c3>:30: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metrics = [load_metric(x) for x in metric_names]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fff0008d3e94c1c87b388945f1836c1"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.8004024933500351}\n",
            "epoch 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/853 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61409cb1c0354d1f9c4506ea10cb530f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.8624864049619454}\n",
            "epoch 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/853 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9e4c873bf0144219f990a3a53d5d65a"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.8852618899996676}\n",
            "epoch 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/853 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a22d20e801b416e9623fa51d5b26a51"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.9007335876804029}\n",
            "epoch 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/853 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c31f6b6f2e64872a058a662fa054b1d"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# setting up the classifier\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SRClassifier(len(vocabulary), 3) # instantiate classifier\n",
        "print(model)\n",
        "\n",
        "# hyperparameters:\n",
        "# TODO: Choose hyperparameters\n",
        "# Note: Maybe start with ~4-5 epochs, it depends on your featurization - you'll likely have to play around with it\n",
        "epochs = 5\n",
        "\n",
        "# optimizer, device, and such\n",
        "# AdamW works well... Try an initial learning rate of 5e-3. Again, you may find that tuning this gives\n",
        "# you better performance!\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3)\n",
        "model.to(device)\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "train(model, train_dataloader, epochs, optimizer, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmyL1wwGLVsL"
      },
      "source": [
        "## Evaluating the classifier\n",
        "We can evaluate the classifer to get an idea of its accuracy before we use it as an oracle in the shift-reduce algorithm. First, load the testing data and generate the testing instances, afterwhich you should instantiate `SRDataset` and `DataLoader` objects similarly to when training. REMEMBER: Now that we're testing, we don't want to augment the vocabulary, thus we pass `is_test=True` to `generate_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1Bw_HcsKqQg"
      },
      "outputs": [],
      "source": [
        "test_data = read_conll('test.conll')\n",
        "\n",
        "X_test, Y_test = generate_training_data(test_data, vocabulary, is_test=True) # is_test is true here!\n",
        "\n",
        "test_dataset = SRDataset(X_test, Y_test)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnGxs_EhLZlW"
      },
      "outputs": [],
      "source": [
        "def evaluate(model: torch.nn.Module, dataloader: TorchDataLoader,\n",
        "             metric_names: List[str]) -> None:\n",
        "  \"\"\"\n",
        "  Function that evaluates a trained model.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      the 1st param name `first`\n",
        "  dataloader : torch.utils.data.DataLoader\n",
        "      the dataloader containing our testing data\n",
        "  metric_names : List[str]\n",
        "      a list of metric names to compute\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  metrics = [load_metric(metric) for metric in metric_names]\n",
        "\n",
        "  print(\"evaluation: \")\n",
        "  progress_bar = tqdm.notebook.tqdm(range(len(dataloader)))\n",
        "\n",
        "  for batch in dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**batch)\n",
        "\n",
        "    predictions = torch.argmax(outputs['output'], dim=1)\n",
        "    references = torch.argmax(outputs['labels'], dim=-1)\n",
        "\n",
        "    for metric in metrics:\n",
        "      metric.add_batch(predictions=predictions, references=references)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "  for metric in metrics:\n",
        "    print(metric.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec0EgjvYPsn7"
      },
      "source": [
        "We can evaluate the model to assess its performance at correctly executing partial parses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_E5EOLcLOp7"
      },
      "outputs": [],
      "source": [
        "metrics = ['accuracy']\n",
        "evaluate(model, test_dataloader, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngVD-J-iLZUZ"
      },
      "source": [
        "# Part 3: Evaluation and Visualization\n",
        "\n",
        "Ok, so we've evaluated the classifier, and it seems to perform well. However, the accuracy score it recieved above doesn't quite represent the performance of our algorithm overall when it is actually applied. To measure this, we use something called UAS - **Unlabeled Attachment Score**. UAS measures the proportion of correctly assigned heads in a full parse. So far, we've only really been considering partial parses. Since a full parse requires sequentially executing partial parses, if one partial parse is wrong, it could influence future partial parses and lead to further incorrect partial parses. Thus, we'd expect our UAS to be *worse* than the accuracy we previously saw, which is more reflective of how well the algorithm is actually doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1l1Gh1J-hyS"
      },
      "source": [
        "## TODO: `get_action`\n",
        "\n",
        "This function takes in the classifier's prediction (in the form of a tensor) and outputs the corresponding action. Make sure to only return an action that is possible given the current stack and buffer state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt9DQWd70ZXu"
      },
      "outputs": [],
      "source": [
        "def get_action(pred: torch.DoubleTensor, stack: List[int],\n",
        "               buf: List[int]) -> Optional[int]:\n",
        "  \"\"\"\n",
        "  Function that takes a prediction (tensor) and finds the highest probability\n",
        "  action that is possible.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  pred : torch.DoubleTensor\n",
        "      our classifier's prediction, the \"output\" field of a torch.nn.Module (such\n",
        "      as our model)\n",
        "  stack : List[int]\n",
        "      the shift-reduce stack\n",
        "  buf : List[int]\n",
        "      the shift-reduce buffer\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Optional[int]: {None, 0, 1, 2}\n",
        "      the predicted action.\n",
        "      None -> no actions can be taken\n",
        "      0 -> arc left\n",
        "      1 -> arc right\n",
        "      2 -> shift\n",
        "  \"\"\"\n",
        "\n",
        "  for i in pred.argsort(descending=True):\n",
        "    if (is_possible(i.item(), stack, buf)):\n",
        "      return i.item()\n",
        "  return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h6m8SC79DWu"
      },
      "source": [
        "## TODO: `model_shift_reduce`\n",
        "Here, we define a version of shift-reduce that consults an SRClassifier, rather than the oracle from Part 1, in order to determine which actions to apply. Use as many helpers from above as needed to write this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05sUoBHa9ruW"
      },
      "outputs": [],
      "source": [
        "def model_shift_reduce(model: torch.nn.Module, example: Dict[str, Any],\n",
        "                       vocab: Dict[str, int]) -> List[Tuple[int, int]]:\n",
        "  \"\"\"\n",
        "  Function that uses our trained classifier to execute the shift-reduce algorithm\n",
        "  and returns the final list of arcs. Note that you will have to cast the output\n",
        "  of `get_features()` to a tensor and load it onto the GPU. You can do this using\n",
        "  `torch.tensor(...).to(device)` or `torch.tensor(..., device=device)`. Note that\n",
        "  `device` was defined a few cells up, when we instantiated our model.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      our trained classifier to use for shift-reduce\n",
        "  example : Dict[str, Any]\n",
        "      a training example produced by read_conll\n",
        "  vocab : Dict[str, int]\n",
        "      our vocabulary\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  List[Tuple[int, int]]\n",
        "      the arcs of the dependency parse tree\n",
        "  \"\"\"\n",
        "\n",
        "  # initialize stack, buffer, and arcs\n",
        "  stack = [None]\n",
        "  buf = [i for i in range(len(example['heads']))]\n",
        "  arcs = []\n",
        "\n",
        "  while len(buf) > 0 or len(stack) > 1:\n",
        "    features = torch.tensor(get_features(stack, buf, example['words'], vocab, is_test), device=device)\n",
        "    action = get_action(model(features)['output'], stack, buf)\n",
        "\n",
        "    if action != None:\n",
        "      apply_action(stack, buf, arcs, action) #Remaking of structures can be done with return\n",
        "    else:\n",
        "      break\n",
        "      print(f\"While loop broken by None return with {len(buf)} remaining elements in buf and {len(stack)} remaining elements in stack\")\n",
        "\n",
        "  return arcs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsdMfwwHMWgK"
      },
      "source": [
        "## TODO: `evaluate_UAS`\n",
        "Now that we can directly compare the true parse to the model's parse, we can tackle evaluating the UAS. To evaluate UAS, we first compute both the correct and predicted parses for each testing phrase and then find the number of arcs in common divided by the number of total arcs. Then, we average these scores across all testing phrases and output the result as UAS of the model on the testing set.\n",
        "\n",
        "$$n: \\text{the total number of example parses}$$\n",
        "$$M_i: \\text{the set of our model's predicted arcs for example }i$$\n",
        "$$O_i: \\text{the set of the oracle's predicted arcs for example }i$$\n",
        "$$\\text{UAS} = \\frac{1}{n} \\sum_{i=1}^n \\frac{|M_i \\cap O_i|}{|O_i|}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpOAq6k3Lj0m"
      },
      "outputs": [],
      "source": [
        "def evaluate_UAS(model: torch.nn.Module, test_examples: List[Dict[str, Any]],\n",
        "                 vocab: Dict[str, int]) -> float:\n",
        "  \"\"\"\n",
        "  Function that calculates UAS.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : torch.nn.Module\n",
        "      our trained classifier\n",
        "  test_examples : List[Dict[str, Any]]\n",
        "      test examples loaded with read_conll\n",
        "  vocab : Dict[str, int]\n",
        "      our word2id vocabulary\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  float\n",
        "      UAS of the classifier on test_examples\n",
        "  \"\"\"\n",
        "  cum_sum = 0.00\n",
        "  for element in test_examples:\n",
        "    featurized_states, ground_truth_actions, oracle_arcs = oracle_shift_reduce(element, vocab, is_test)\n",
        "    model_arcs = model_shift_reduce(model, element, vocab)\n",
        "    intersection = 0.00\n",
        "    for i, oracle_arc in enumerate(oracle_arcs):\n",
        "      if i < len(model_arcs):\n",
        "        if model_arcs[i] == oracle_arc:\n",
        "          intersection += 1.00\n",
        "\n",
        "    cum_sum += intersection/len(oracle_arcs)\n",
        "\n",
        "  return cum_sum/len(test_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUCojOEDMvhg"
      },
      "source": [
        "### Baseline UAS\n",
        "Of course, we'd have no idea if our model was useful if we didn't evaluate a baseline model too. The baseline model should output something of the same format as the `SRClassifier`, except it just outputs a tensor with randomly ordered values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LyVbJEEdPji"
      },
      "outputs": [],
      "source": [
        "# model that takes input in format given by SRDataset\n",
        "class SRBaseline(torch.nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(SRBaseline, self).__init__()\n",
        "\n",
        "    def forward(self, inputs: Any) -> Dict[str, torch.Tensor]:\n",
        "        return {'output': torch.randperm(3)[None, :]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTShIFtxNNOQ"
      },
      "source": [
        "## TODO: Final Scoring\n",
        "Evaluate the baseline UAS and compare it to that of our model. For this function, directly use the CoNLL dataset as the argument to `test_examples`, not the dataloader we had used for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYWhgrbfNWqR"
      },
      "outputs": [],
      "source": [
        "model_uas = evaluate_UAS(model, test_data, vocabulary)\n",
        "baseline_model = SRBaseline(train_dataset)\n",
        "baseline_uas = evaluate_UAS(baseline_model, test_data, vocabulary)\n",
        "print(f\"Model UAS: {model_uas}, baseline: {baseline_uas}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I47uU9Iboy0T",
        "outputId": "92146fb9-6db5-4ba7-c9d6-a8ef98a549b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[0;32m<ipython-input-7-e77cac756e29>\u001b[0m(34)\u001b[0;36mis_possible\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     32 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     33 \u001b[0;31m  \u001b[0mmatch\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 34 \u001b[0;31m    \u001b[0mcase\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     35 \u001b[0;31m      \u001b[0;32mif\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> action\n",
            "tensor([2, 1, 0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCYMfPeVNXK2"
      },
      "source": [
        "The model should be over three times better than the baseline. For full credit, your model should have a UAS of over 65%, so you may need to make adjustments to your model, featurization, and hyperparameters in order to improve your score. If you submit with a UAS of under 65%, you'll recieve partial credit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XwnddayNc9F"
      },
      "source": [
        "# Part 4: Conceptual\n",
        "Let's explore some of the parses visually. The following functions deal with reformating and displaying dependency parses. You'll only need to use `display_parse`, check its signature. Additionally, you'll be asked to compare the parses that your model creates with real parses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnHz17-xbrug"
      },
      "source": [
        "## Helpers and examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDSsoEAL59a5"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.displacy.render import DependencyRenderer\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def reformat_dep(arcs: List[Tuple[int, int]], words: List[str]) -> Tuple[List[str], List[int]]:\n",
        "  \"\"\"\n",
        "  Function that takes in a set of arcs and produces a list of heads,\n",
        "  in the same format we described at the beginning.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  arcs : List[Tuple[int, int]]\n",
        "      a list of arcs returned by model_shift_reduce\n",
        "  words : List[str]\n",
        "      a list of words from a testing example\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Tuple[List[str], List[int]]\n",
        "      the words parameters and the list of heads\n",
        "  \"\"\"\n",
        "  heads = list(range(len(words)))\n",
        "  for arc in arcs:\n",
        "    heads[arc[1]] = arc[0]\n",
        "  return words, heads\n",
        "\n",
        "def parse_for_displacy(doc: List[str], heads: List[int]) -> Dict[str, Any]:\n",
        "  \"\"\"\n",
        "  Function that takes in a sentence and a list of heads and reformats them into\n",
        "  something that can be rendered using displacy.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  doc : List[str]\n",
        "      a list of words in a sentence\n",
        "  heads : List[int]\n",
        "      a list of indices indexing `doc` that represent the head of each word\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Dict[str, Any]\n",
        "      the parsed sentence in a format friendly to displacy\n",
        "  \"\"\"\n",
        "  #doc = ['word1', 'word2', ...]\n",
        "  #heads = [idx_of_head_of_word1, idx_of_head_of_word2, ...]\n",
        "  settings = {\n",
        "      \"lang\": 'en',\n",
        "      \"direction\": 'ltr',\n",
        "  }\n",
        "  words = [\n",
        "      {\n",
        "          \"text\": w,#w.text,\n",
        "          \"tag\": '',#w.tag_ if fine_grained else w.pos_,\n",
        "          \"lemma\": w#w.lemma_ if add_lemma else None,\n",
        "      }\n",
        "      for w in doc\n",
        "  ]\n",
        "  arcs = []\n",
        "  for i,word in enumerate(doc):\n",
        "      if heads[i] == None:\n",
        "        continue\n",
        "      if i < heads[i]:\n",
        "          arcs.append(\n",
        "              {\"start\": i, \"end\": heads[i], \"label\": '', \"dir\": \"left\"}\n",
        "          )\n",
        "      elif i > heads[i]:\n",
        "          arcs.append(\n",
        "              {\n",
        "                  \"start\": heads[i],\n",
        "                  \"end\": i,\n",
        "                  \"label\": '',\n",
        "                  \"dir\": \"right\",\n",
        "              }\n",
        "          )\n",
        "  return {\"words\": words, \"arcs\": arcs, \"settings\": settings}\n",
        "\n",
        "def display_parse(arcs: List[Tuple[int, int]], words: List[str]) -> None:\n",
        "  \"\"\"\n",
        "  Function that renders and displays a parsed sentence.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  arcs : List[Tuple[int, int]]\n",
        "      the final set of arcs returned by our shift-reduce algorithm\n",
        "  words : List[str]\n",
        "      the words that `arcs` connects\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  parsed=[parse_for_displacy(*reformat_dep(arcs, words))]\n",
        "  renderer = DependencyRenderer()\n",
        "  html = renderer.render(parsed, page=False, minify=False).strip()\n",
        "  display(HTML('<span class=\"tex2jax_ignore\">{}</span>'.format(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_EIFr2hOc5D"
      },
      "source": [
        "Here's an example, where we try to parse the sentence \"I prefer the morning flight through Denver.\". Note that punctuation is treated as its own token here. Below is a brief summary of how you need to format punctuation and contractions such that they're in the same format as the training/testing data we used previously:\n",
        "\n",
        "`\"weren't\" -> [\"were\", \"n't\"]`\n",
        "\n",
        "`\"Stock Market's\" -> [\"Stock\", \"Market\", \"'s\"]`\n",
        "\n",
        "`[\"'quoted text'\"] -> [\"``\", \"quoted\", \"text\", \"''\"]`\n",
        "\n",
        "`[\"22%\"] -> [\"22\", \"%\"]`\n",
        "\n",
        "`[\"$15\"] -> [\"$\", \"15\"]`\n",
        "\n",
        "Feel free to download `train.conll` or `test.conll` and take a peek at how the examples are tokenized.\n",
        "\n",
        "Additionally, we didn't do any lowercasing on the dataset, since it actually slightly harms performance on this task (think about why it might), so also don't do lowercasing when trying out your own sentences (see that \"Denver\" stays capitalized)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhSWmkjX7gkj"
      },
      "outputs": [],
      "source": [
        "example = {'words': \"I prefer the morning flight through Denver .\".split(\" \"), 'heads': [1, None, 4, 4, 1, 6, 4, 1]}\n",
        "\n",
        "model_arcs = model_shift_reduce(model, example, vocabulary) # get the model's parse\n",
        "_, _, true_arcs = oracle_shift_reduce(example, vocabulary, is_test=True) # get the true parse\n",
        "\n",
        "print(\"Predicted parse:\")\n",
        "display_parse(model_arcs, example['words'])\n",
        "print(\"Actual parse:\")\n",
        "display_parse(true_arcs, example['words'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBJnOgODbyBT"
      },
      "source": [
        "## TODO: Conceptual question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak5gdrzXYRW1"
      },
      "source": [
        "Now, come up with some of your own examples and visualize them! Try to find some scenarios where the parses your model produces aren't as accurate, **and comment on them**. A great tool to generate the correct parses is [this site](https://corenlp.run/) by CoreNLP. Select only 'dependency parse' in the annotation selection box, type in your examples, and hit 'Submit' to see the parses!\n",
        "\n",
        "Recall the format of the head list: The entry with value `None` is the root word, and the entries at all other words are the index of their respective heads! In the example above, 'prefer' is the root word (thus has `None` as its head), so any word in the word list who's head is 'prefer' has a `1` as its head value (since 'prefer' is the second word), and so on. You'll need to encode the correct parse given by CoreNLP into the head list, so make sure to triple-check that you got it right.\n",
        "\n",
        "If you take a look at the kinds of words frequently used in the training dataset (there's a theme, take a look), it may explain some behaviors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TflYd7Z9Z_uz"
      },
      "source": [
        "TODO: Fill me in!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TVumhUTaAYn"
      },
      "outputs": [],
      "source": [
        "# TODO: code here! (feel free to make more cells.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_q4KnTuRiij"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqOiVErKRn0R"
      },
      "source": [
        "Download this notebook as a .ipynb and .py file and submit it to Gradescope. Before doing so, additionally paste a link to your notebook in the text cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuRTnYnFRwl_"
      },
      "source": [
        "**LINK TO THIS NOTEBOOK:** [...](https://)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b08d44531fd42869ebf57ca49c5cdb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18edc01a7f044098baf08ddf59e84f77",
              "IPY_MODEL_34cdb37a383c42d69011f7487c8d54ec",
              "IPY_MODEL_3a24df6efc3b42dfb788c52aedd1cf58"
            ],
            "layout": "IPY_MODEL_fe23141485bb442293ce090165342c51"
          }
        },
        "18edc01a7f044098baf08ddf59e84f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_620c305ab31142c0ae3f50db8d5b04b3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6ea26680627d4976be43b00bd236867a",
            "value": "100%"
          }
        },
        "34cdb37a383c42d69011f7487c8d54ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ce14000deb420da4ae0e425e83be48",
            "max": 853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75e65f7f34a34e49ac756da0bfbad18c",
            "value": 853
          }
        },
        "3a24df6efc3b42dfb788c52aedd1cf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7179b5b15ecc4d6daafa2bca091a6f9e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0edf89f1c4f34cfba92a3da32aae0a64",
            "value": " 853/853 [01:03&lt;00:00, 69.24it/s]"
          }
        },
        "fe23141485bb442293ce090165342c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620c305ab31142c0ae3f50db8d5b04b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea26680627d4976be43b00bd236867a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ce14000deb420da4ae0e425e83be48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e65f7f34a34e49ac756da0bfbad18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7179b5b15ecc4d6daafa2bca091a6f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edf89f1c4f34cfba92a3da32aae0a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b77dbd8c73f4210b50cecc05a1944ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43944429ce824e859a498485a7735e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a511e13156844d886be1c826081a9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77655841d8b5479d91e23dbafdb9facd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1023c651431549cda299a0ca3f973d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60866d5b62d7469484bea75436ea8c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9778bbc1d93c4c10b9d94d114d0f30e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a511e13156844d886be1c826081a9bc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_77655841d8b5479d91e23dbafdb9facd",
            "value": "Downloading builder script: "
          }
        },
        "77ba2119440a487ca55ff75502ff599b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b77dbd8c73f4210b50cecc05a1944ba",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43944429ce824e859a498485a7735e5c",
            "value": 1652
          }
        },
        "23e5be392fc447ec9853741cd7bfa395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1023c651431549cda299a0ca3f973d79",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_60866d5b62d7469484bea75436ea8c98",
            "value": " 4.21k/? [00:00&lt;00:00, 157kB/s]"
          }
        },
        "d24b1479ffef42ed94f2a44035e52250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fff0008d3e94c1c87b388945f1836c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9778bbc1d93c4c10b9d94d114d0f30e7",
              "IPY_MODEL_77ba2119440a487ca55ff75502ff599b",
              "IPY_MODEL_23e5be392fc447ec9853741cd7bfa395"
            ],
            "layout": "IPY_MODEL_d24b1479ffef42ed94f2a44035e52250"
          }
        },
        "06f8da5c3fcb4c6b8fe1cc9def2cb76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b79fd6833e34f7997e48db3940c235f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "183b9fa2fc1642488c94b6d2476bef90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1b04350b314902845abe15ecdef420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "641717f97dfd4d8da8b2981e239b1add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd30897f4ad44aaa87731b216f2a12d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b5650adb104130bce2ce14c0547b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183b9fa2fc1642488c94b6d2476bef90",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3c1b04350b314902845abe15ecdef420",
            "value": "100%"
          }
        },
        "d20f0a3bbdc64ccc85cdec1e1d42f985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06f8da5c3fcb4c6b8fe1cc9def2cb76b",
            "max": 853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b79fd6833e34f7997e48db3940c235f",
            "value": 853
          }
        },
        "4e592b10ea8a4a668c250d97c2121980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641717f97dfd4d8da8b2981e239b1add",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bd30897f4ad44aaa87731b216f2a12d1",
            "value": " 853/853 [00:43&lt;00:00, 72.16it/s]"
          }
        },
        "2f2890d334bb40a1abacabc79411286a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61409cb1c0354d1f9c4506ea10cb530f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81b5650adb104130bce2ce14c0547b15",
              "IPY_MODEL_d20f0a3bbdc64ccc85cdec1e1d42f985",
              "IPY_MODEL_4e592b10ea8a4a668c250d97c2121980"
            ],
            "layout": "IPY_MODEL_2f2890d334bb40a1abacabc79411286a"
          }
        },
        "4b21be59abbd4a1590f03554cc2f3159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7a65096b3f495b8fe592405348cc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f4e468938e34ac78392caafc4e57c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df61f576e9004a3aacab8660f600cde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d06bd65ef4c416184c51b55dc73780d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142b61b77d6d43688054531481284881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ee21c6dad034a64ad8423ccdf3a0bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4e468938e34ac78392caafc4e57c30",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_df61f576e9004a3aacab8660f600cde4",
            "value": "100%"
          }
        },
        "0ba33faafc924da298cd29073e9956fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b21be59abbd4a1590f03554cc2f3159",
            "max": 853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba7a65096b3f495b8fe592405348cc91",
            "value": 853
          }
        },
        "d86cc9526321403c895e5f8f76f5e5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d06bd65ef4c416184c51b55dc73780d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_142b61b77d6d43688054531481284881",
            "value": " 853/853 [00:28&lt;00:00, 47.20it/s]"
          }
        },
        "f5b9a617689e438f85f373b9ad308266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e4c873bf0144219f990a3a53d5d65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ee21c6dad034a64ad8423ccdf3a0bb1",
              "IPY_MODEL_0ba33faafc924da298cd29073e9956fd",
              "IPY_MODEL_d86cc9526321403c895e5f8f76f5e5d5"
            ],
            "layout": "IPY_MODEL_f5b9a617689e438f85f373b9ad308266"
          }
        },
        "05e30a2ff9804d0aaf5a1fcfd4087912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81fc197c9851485f8d99d1c7e805a996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ecc88db3214439db4a43368a8b9231a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7318698d2a346da9661e669cd82b962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd05603628a247c08e4aa8aab4494e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9957d2a7778f4e42a627a6f8c7c36c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c73e558ee4844f808057e0c5c998f14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecc88db3214439db4a43368a8b9231a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a7318698d2a346da9661e669cd82b962",
            "value": " 99%"
          }
        },
        "76f3922eb171443387dca4bf2f81ac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e30a2ff9804d0aaf5a1fcfd4087912",
            "max": 853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81fc197c9851485f8d99d1c7e805a996",
            "value": 845
          }
        },
        "9c4a01058ebd43969dbd4ca0610257b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd05603628a247c08e4aa8aab4494e14",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9957d2a7778f4e42a627a6f8c7c36c06",
            "value": " 845/853 [00:14&lt;00:00, 72.49it/s]"
          }
        },
        "9c3c8d6358b24cc2b7cdd6777f56ca96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a22d20e801b416e9623fa51d5b26a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c73e558ee4844f808057e0c5c998f14b",
              "IPY_MODEL_76f3922eb171443387dca4bf2f81ac2f",
              "IPY_MODEL_9c4a01058ebd43969dbd4ca0610257b7"
            ],
            "layout": "IPY_MODEL_9c3c8d6358b24cc2b7cdd6777f56ca96"
          }
        },
        "f6ccef61bda445618d81b7076c8b48c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330898310df6496ca68f35531c50ce98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de66e34d5acd45a3834237b6c7358854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b73d99eff4f94ba2aa65c7d06805f0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ad7694ef57441608ec5877e9c6f9f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a0cb870e30456f94b43ff0a76b15fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72734e033887472290c84d8e0c447f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de66e34d5acd45a3834237b6c7358854",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b73d99eff4f94ba2aa65c7d06805f0f6",
            "value": " 17%"
          }
        },
        "f3fe611655314879bcb5efcae3da43bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ccef61bda445618d81b7076c8b48c9",
            "max": 853,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_330898310df6496ca68f35531c50ce98",
            "value": 142
          }
        },
        "170b6ffedfcb42408d8099c405f3f956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad7694ef57441608ec5877e9c6f9f24",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e5a0cb870e30456f94b43ff0a76b15fc",
            "value": " 142/853 [00:02&lt;00:10, 70.72it/s]"
          }
        },
        "974a72ae732f43fe858a2ae12ffa0f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c31f6b6f2e64872a058a662fa054b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72734e033887472290c84d8e0c447f55",
              "IPY_MODEL_f3fe611655314879bcb5efcae3da43bc",
              "IPY_MODEL_170b6ffedfcb42408d8099c405f3f956"
            ],
            "layout": "IPY_MODEL_974a72ae732f43fe858a2ae12ffa0f18"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}